{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90454e95",
   "metadata": {},
   "source": [
    "# Lab 6 - Gaussian Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c5703ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cmdstanpy import CmdStanModel\n",
    "\n",
    "import arviz as az\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2010f5",
   "metadata": {},
   "source": [
    "In general, Gaussian Process (GP) is a stochastic process used for modeling data, which were observed over time, space or both. Main thing that can characterise GP is that is a kind of generalization of normal probability distributions, where each of them describes a random variable (scalar or vector if we deal with multivariate distribution).\n",
    "\n",
    "Following definition captures the essence of Gaussian Process: \n",
    "\n",
    "A Gaussian process is a collection of random variables, any Gaussian process finite number of which have a joint Gaussian distribution.\n",
    "\n",
    "\n",
    "If we define mean function $m(x)$ and the covariance function mean function $k(x,x')$ of a real process $f(x)$ as:\n",
    "\\begin{equation}\n",
    "m(x) = E[f(x)]\n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "k(x,x') = E[f(x)-m(x))(f(x')-m(x'))]\n",
    "\\end{equation}\n",
    "Then we can define GP can as:\n",
    "\\begin{equation}\n",
    "\\label{eq:gpmain}\n",
    "f(x) \\sim GP(m(x),k(x,x'))\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "GP can be fully determined by only declaring mean and covariance functions. Mean in most cases is set to value \"0\", because such a setting can be useful, simplifies matters and is not a difficult requirement to fulfill. Of course, there are examples\n",
    "where we would like to change the mean e.g. for better model interpretability or the \n",
    "specification of our prior. Covariance function (also called kernel function) represents\n",
    "a similarity between data points. Note that usually covariance is chosen from\n",
    "the set of already defined functions. The one should at least pick one, which represents\n",
    "prior beliefs of the problem. But in fact, covariance function can be any function, which\n",
    "has the property of generating a positive definite covariance matrix. Anyway, creating \n",
    "and defining new covariance functions, which will simultaneously be correct and have a\n",
    "practical usage, can be really difficult\n",
    "\n",
    "The most basic and common kernel function is Radial Basis Function (RBF), which is defined with the formula:\n",
    "\\begin{equation}\n",
    "\\label{eq:rbf}\n",
    "k\\left(x_{i}, x_{j}\\right)=\\exp \\left(-\\frac{d\\left(x_{i}, x_{j}\\right)^{2}}{2 l^{2}}\\right)\n",
    "\\end{equation}\n",
    "Its main property is that its value is usually only dependent on the distance from the specified point. The parameter which RBF kernel uses is $l$ as a characteristic length scale. RBF is infinitely differentiable. That means the GP with this kernel has a mean square derivatives for all orders. Other worth noting kernel, in terms of our classess is one from exponentiated quadratic family, where $\\rho$ is length-scale and $\\alpha$ is marginal deviation:\n",
    "$$\n",
    "k\\left(x_{1}, x_{2}\\right)=\\alpha^{2} \\exp \\left(-\\frac{1}{2}\\left(\\frac{\\left|x_{1}-x_{2}\\right|}{\\rho}\\right)^{2}\\right)\n",
    "$$\n",
    "Gaussian Process is growing in popularity of usage in domains connected with statistics and machine learning. It is especially efficient solution, while we are dealing with a problem of obtaining data e.g. for faulty cases or just an overall lack of comprehensive data and if we want to obtain not only prediction but also confidence interval. Main areas where GP is used for are: regression, prediction, classification and identification. On this classes we will focuse on a simple task of regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5df2c0",
   "metadata": {},
   "source": [
    "### Task 1: simulating from Gaussian Process model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1542b3b0",
   "metadata": {},
   "source": [
    "To make any simulations, first you need a set of observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87dc0f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Observed data\n",
    "x_obs = [-10, -8, -6, -4, -2, 0, 2, 4, 6, 8, 10]\n",
    "y_obs = [0.328572824089476, 4.20607004111644, 1.35507551134795,\n",
    "0.161608755204364, -5.42320349780782, -3.05851276224202, -0.0764172642034502,\n",
    "-4.55218472276499, -0.902226297922731, -5.8609833528976, -1.05854090910473]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c488b57",
   "metadata": {},
   "source": [
    "Model also needs sampling space and the indexes of where our observed data resides there. \n",
    "For your convenience, we provide them below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cc64fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_predict = np.linspace(-11,11,551,endpoint=True)\n",
    "observed_idx = [26, 76, 126, 176, 226, 276, 326, 376, 426, 476, 526]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc7b7ff",
   "metadata": {},
   "source": [
    "In this example we are using kernel from exponentiated quadratic family, so we need to provide its hyperparameters (alpha and rho). Moreover, for sample generation, we would like to set a sigma value. Let's start with some arbitrarily selected parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a958c173",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 3\n",
    "rho = 5.5\n",
    "sigma = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e110baf",
   "metadata": {},
   "source": [
    "Now we can create a model and sample from it. Do not forget to define proper data value based on requirements from stan model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f969aa90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cmdstanpy:found newer exe file, not recompiling\n"
     ]
    }
   ],
   "source": [
    "model = CmdStanModel(stan_file='gaussian_process.stan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69ce7ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cmdstanpy:CmdStan start procesing\n",
      "chain 1 |\u001b[33m          \u001b[0m| 00:00 Status\n",
      "\u001b[A\n",
      "\n",
      "chain 1 |\u001b[33m▍         \u001b[0m| 00:00 Status\n",
      "\u001b[A\n",
      "\n",
      "chain 1 |\u001b[33m▉         \u001b[0m| 00:02 Iteration:    1 / 2000 [  0%]  (Warmup)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1 |\u001b[33m█▎        \u001b[0m| 00:04 Iteration:  100 / 2000 [  5%]  (Warmup)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1 |\u001b[33m█▊        \u001b[0m| 00:07 Iteration:  200 / 2000 [ 10%]  (Warmup)\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "data1 = {\n",
    "    'N_predict': len(x_predict),\n",
    "    'x_predict': x_predict,\n",
    "    'N_obs': len(observed_idx),\n",
    "    'y_obs': y_obs,\n",
    "    'observed_idx': observed_idx,\n",
    "    'rho': rho,\n",
    "    'alpha': alpha,\n",
    "    'sigma': sigma\n",
    "}\n",
    "\n",
    "result = model.sample(data=data1, chains = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852a2439",
   "metadata": {},
   "source": [
    "Your task now is to:\n",
    "- plot few (about 5-10) samples generated from model\n",
    "- plot mean value from model with its confidence interval (standar deviation, using errorbar function)\n",
    "\n",
    "Also on each plot place points with obsserved data. Repeat the steps for two other parameters sets of your choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dff3190",
   "metadata": {},
   "outputs": [],
   "source": [
    "rho2 = 4\n",
    "alpha2= 6\n",
    "sigma2 = 3\n",
    "\n",
    "rho3 = 2\n",
    "alpha3 = 3\n",
    "sigma3 = 5.5\n",
    "\n",
    "data2 = {\n",
    "    'N_predict': len(x_predict),\n",
    "    'x_predict': x_predict,\n",
    "    'N_obs': len(observed_idx),\n",
    "    'y_obs': y_obs,\n",
    "    'observed_idx': observed_idx,\n",
    "    'rho': rho2,\n",
    "    'alpha': alpha2,\n",
    "    'sigma': sigma2\n",
    "}\n",
    "\n",
    "data3 = {\n",
    "    'N_predict': len(x_predict),\n",
    "    'x_predict': x_predict,\n",
    "    'N_obs': len(observed_idx),\n",
    "    'y_obs': y_obs,\n",
    "    'observed_idx': observed_idx,\n",
    "    'rho': rho3,\n",
    "    'alpha': alpha3,\n",
    "    'sigma': sigma3\n",
    "}\n",
    "\n",
    "data = [data1, data2, data3]\n",
    "\n",
    "for d in data:\n",
    "\n",
    "    N_plots = 5\n",
    "    result = model.sample(data=d, chains = 4)\n",
    "    y_predict = result.stan_variable('y_predict')\n",
    "\n",
    "    for p in range(N_plots):\n",
    "        y = y_predict[:, p]\n",
    "        plt.plot(y)\n",
    "        plt.scatter(observed_idx, y_obs, color='r', zorder=5)\n",
    "        plt.show()\n",
    "        mean = np.mean(y)\n",
    "        std = np.std(y)\n",
    "        plt.errorbar(range(len(y)), [mean]*len(y), std, ecolor='m')\n",
    "        plt.scatter(range(len(y)), [mean]*len(y))\n",
    "        plt.scatter(observed_idx, y_obs, color='r', zorder=5)\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612ecb18",
   "metadata": {},
   "source": [
    "### Task 2: optimize hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cf4f85",
   "metadata": {},
   "source": [
    "To achive better results of GP fitting for our observed data, we need to oprimize its parameters. We can do that by using maximum marginal likelihood estimation. It can be done by placing parameters in \"parameter\" block in stan model and using \"optimize\" method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c710bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cmdstanpy:compiling stan file C:\\Users\\awitc\\Desktop\\DataAnalytics\\Lab6\\gaussian_process_optimize.stan to exe file C:\\Users\\awitc\\Desktop\\DataAnalytics\\Lab6\\gaussian_process_optimize.exe\n",
      "INFO:cmdstanpy:compiled model executable: C:\\Users\\awitc\\Desktop\\DataAnalytics\\Lab6\\gaussian_process_optimize.exe\n",
      "WARNING:cmdstanpy:Stan compiler has produced 2 warnings:\n",
      "WARNING:cmdstanpy:\n",
      "--- Translating Stan model to C++ code ---\n",
      "bin/stanc.exe  --o=C:/Users/awitc/Desktop/DataAnalytics/Lab6/gaussian_process_optimize.hpp C:/Users/awitc/Desktop/DataAnalytics/Lab6/gaussian_process_optimize.stan\n",
      "Warning in 'C:/Users/awitc/Desktop/DataAnalytics/Lab6/gaussian_process_optimize.stan', line 3, column 4: Declaration\n",
      "    of arrays by placing brackets after a variable name is deprecated and\n",
      "    will be removed in Stan 2.32.0. Instead use the array keyword before the\n",
      "    type. This can be changed automatically using the auto-format flag to\n",
      "    stanc\n",
      "Warning in 'C:/Users/awitc/Desktop/DataAnalytics/Lab6/gaussian_process_optimize.stan', line 14, column 31: cov_exp_quad\n",
      "    is deprecated and will be removed in Stan 2.32.0. Use gp_exp_quad_cov\n",
      "    instead. This can be automatically changed using the canonicalize flag\n",
      "    for stanc\n",
      "\n",
      "--- Compiling, linking C++ code ---\n",
      "g++ -std=c++1y -m64 -D_REENTRANT -Wall -Wno-unused-function -Wno-uninitialized -Wno-unused-but-set-variable -Wno-unused-variable -Wno-sign-compare -Wno-unused-local-typedefs -Wno-int-in-bool-context -Wno-attributes -Wno-ignored-attributes      -I stan/lib/stan_math/lib/tbb_2020.3/include    -O3 -I src -I stan/src -I lib/rapidjson_1.1.0/ -I lib/CLI11-1.9.1/ -I stan/lib/stan_math/ -I stan/lib/stan_math/lib/eigen_3.3.9 -I stan/lib/stan_math/lib/boost_1.75.0 -I stan/lib/stan_math/lib/sundials_6.0.0/include -I stan/lib/stan_math/lib/sundials_6.0.0/src/sundials  -D_USE_MATH_DEFINES  -DBOOST_DISABLE_ASSERTS          -c  -x c++ -o C:/Users/awitc/Desktop/DataAnalytics/Lab6/gaussian_process_optimize.o C:/Users/awitc/Desktop/DataAnalytics/Lab6/gaussian_process_optimize.hpp\n",
      "g++ -std=c++1y -m64 -D_REENTRANT -Wall -Wno-unused-function -Wno-uninitialized -Wno-unused-but-set-variable -Wno-unused-variable -Wno-sign-compare -Wno-unused-local-typedefs -Wno-int-in-bool-context -Wno-attributes -Wno-ignored-attributes      -I stan/lib/stan_math/lib/tbb_2020.3/include    -O3 -I src -I stan/src -I lib/rapidjson_1.1.0/ -I lib/CLI11-1.9.1/ -I stan/lib/stan_math/ -I stan/lib/stan_math/lib/eigen_3.3.9 -I stan/lib/stan_math/lib/boost_1.75.0 -I stan/lib/stan_math/lib/sundials_6.0.0/include -I stan/lib/stan_math/lib/sundials_6.0.0/src/sundials  -D_USE_MATH_DEFINES  -DBOOST_DISABLE_ASSERTS                -Wl,-L,\"C:/Users/awitc/anaconda3/Library/bin/cmdstan/stan/lib/stan_math/lib/tbb\" -Wl,-rpath,\"C:/Users/awitc/anaconda3/Library/bin/cmdstan/stan/lib/stan_math/lib/tbb\"      C:/Users/awitc/Desktop/DataAnalytics/Lab6/gaussian_process_optimize.o src/cmdstan/main.o  -static-libgcc -static-libstdc++      -Wl,-L,\"C:/Users/awitc/anaconda3/Library/bin/cmdstan/stan/lib/stan_math/lib/tbb\" -Wl,-rpath,\"C:/Users/awitc/anaconda3/Library/bin/cmdstan/stan/lib/stan_math/lib/tbb\"   stan/lib/stan_math/lib/sundials_6.0.0/lib/libsundials_nvecserial.a stan/lib/stan_math/lib/sundials_6.0.0/lib/libsundials_cvodes.a stan/lib/stan_math/lib/sundials_6.0.0/lib/libsundials_idas.a stan/lib/stan_math/lib/sundials_6.0.0/lib/libsundials_kinsol.a  stan/lib/stan_math/lib/tbb/tbb.dll -o C:/Users/awitc/Desktop/DataAnalytics/Lab6/gaussian_process_optimize.exe\n",
      "rm -f C:/Users/awitc/Desktop/DataAnalytics/Lab6/gaussian_process_optimize.o\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model2 = CmdStanModel(stan_file='gaussian_process_optimize.stan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b212b612",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cmdstanpy:Chain [1] start processing\n",
      "INFO:cmdstanpy:Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rho: 1.13658\n",
      "alpha: 3.1811\n",
      "sigma: 0.196539\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "            'N_obs': len(observed_idx),\n",
    "            'y_obs': y_obs,\n",
    "            'x_obs': x_obs\n",
    "        }\n",
    "\n",
    "result2 = model2.optimize(data=data, seed=5838298)\n",
    "\n",
    "for variable in ['rho', 'alpha', 'sigma']:\n",
    "    print(f'{variable}: {result2.stan_variable(variable)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694aedb2",
   "metadata": {},
   "source": [
    "Optimize parameters with mentioned method and generate new samples with model from task 1. Of course use just aquired parameters. Do not forget to specify data variable based on stan model. \n",
    "What can your say about results in comparison to ones from task 1?\n",
    "Did the GP perform well in the task of regression? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d53a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rho_result = result2.stan_variable('rho')\n",
    "alpha_result = result2.stan_variable('alpha')\n",
    "sigma_result = result2.stan_variable('sigma')\n",
    "\n",
    "data2 = {\n",
    "    'N_predict': len(x_predict),\n",
    "    'x_predict': x_predict,\n",
    "    'N_obs': len(observed_idx),\n",
    "    'y_obs': y_obs,\n",
    "    'observed_idx': observed_idx,\n",
    "    'rho': rho2,\n",
    "    'alpha': alpha2,\n",
    "    'sigma': sigma2\n",
    "}\n",
    "\n",
    "N_plots = 5\n",
    "result = model.sample(data=data2, chains = 4)\n",
    "y_predict = result.stan_variable('y_predict')\n",
    "\n",
    "for p in range(N_plots):\n",
    "    y = y_predict[:, p]\n",
    "    plt.plot(y)\n",
    "    plt.scatter(observed_idx, y_obs, color='r', zorder=5)\n",
    "    plt.show()\n",
    "    mean = np.mean(y)\n",
    "    std = np.std(y)\n",
    "    plt.errorbar(range(len(y)), [mean]*len(y), std, ecolor='m')\n",
    "    plt.scatter(range(len(y)), [mean]*len(y))\n",
    "    plt.scatter(observed_idx, y_obs, color='r', zorder=5)\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7f55e8659d8335c9c086356a4f50ede682aa20dda0a5da3205261e9181bdc4e6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
